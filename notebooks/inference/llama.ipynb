{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177573a0-20cf-4980-827d-a935b48ec24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1714: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/modeling_utils.py:2193: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc7ac62c9804e7bb12a103e4282283e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "# Load llama\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers, torch, os\n",
    "\n",
    "model_slug = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "\n",
    "HF_HUB_KEY = os.environ.get('HF_HUB_KEY')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_slug, use_auth_token=HF_HUB_KEY, padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_slug,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "#     load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    use_auth_token=HF_HUB_KEY,\n",
    ")\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    batch_size=4,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b4c6a4-e255-4626-a116-1255bac2bb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"  Certainly! Risotto is a classic Italian dish made with Arborio rice, flavorful broth, and a variety of ingredients such as vegetables, meat, or seafood. Here's a basic recipe for making a delicious risotto at home:\\n\\nIngredients:\\n\\n* 1 cup Arborio rice\\n* 4 cups vegetable or chicken broth, warmed\\n* 2 tablespoons olive oil\\n* 1 small onion, finely chopped\\n* 2 cloves garlic, minced\\n* 1 cup mixed mushrooms (such as cremini, shiitake, and button), sliced\\n* 1 cup white wine (optional)\\n* 1/4 cup grated Parmesan cheese\\n* Salt and pepper, to taste\\n* Fresh parsley, chopped (optional)\\n\\nInstructions:\\n\\n1. Heat the olive oil in a large saucepan over medium heat. Add the chopped onion and cook until softened, about 3-4 minutes.\\n2. Add the minced garlic and cook for another minute, stirring constantly to prevent burning.\\n3. Add the Arborio rice and stir to coat the rice with the oil and mix with the onion and garlic. Cook for 1-2 minutes.\\n4. Add the warmed broth, 1/2 cup at a time, stirring constantly and allowing each portion to be absorbed before adding the next. It should take about 20-25 minutes for all the broth to be absorbed and the rice to be cooked.\\n5. During the cooking process, add the sliced mushrooms and cook until they release their moisture and start to brown, about 5-7 minutes.\\n6. If using white wine, add it to the rice mixture after 10 minutes of cooking and stir to combine.\\n7. When the rice is cooked and creamy, remove the saucepan from the heat. Stir in the grated Parmesan cheese and season with salt and pepper to taste.\\n8. Serve the risotto immediately, garnished with chopped parsley if desired.\\n\\nNote: It's important to use a medium-low heat\"}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_prompt_llama(instruction, preamble=None):\n",
    "    template = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "<</SYS>>\n",
    "\n",
    "{instruction} [/INST]\"\"\"\n",
    "    if preamble is not None:\n",
    "        return template.format(instruction=instruction, preamble=preamble)\n",
    "    else:\n",
    "        return template.format(instruction=instruction, preamble='')\n",
    "\n",
    "pipeline(\n",
    "       format_prompt_llama('Can you tell me how to make a risotto?'),\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        return_full_text=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97028bd-4af1-4d2b-8187-363eafb8d3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "model = model.to_bettertransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "050dfc0b-b5a5-4402-8634-589770d03b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2700/2700 [5:24:00<00:00,  7.20s/it]\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "with jsonlines.open('./prompts_augmented_v2.jsonl') as reader:\n",
    "    prompts = [row for row in reader]\n",
    "    \n",
    "def format_prompt_llama(instruction):\n",
    "    template = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "<</SYS>>\n",
    "\n",
    "{instruction} [/INST]\"\"\"\n",
    "    return template.format(instruction=instruction)\n",
    "    \n",
    "continuations = []\n",
    "# for row in tqdm(prompts):]\n",
    "pipeline.tokenizer.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_list)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.original_list[i]\n",
    "\n",
    "ds = ListDataset([format_prompt_llama(row['prompt']) for row in prompts])\n",
    "torch.cuda.empty_cache()\n",
    "sequences = []\n",
    "for seq in tqdm(pipeline(\n",
    "   ds,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False,\n",
    "    # batch_size=4,\n",
    "), total=len(prompts)):\n",
    "    sequences.extend(seq)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "for x, row in zip(sequences, prompts):\n",
    "    continuation = x['generated_text']\n",
    "    continuations.append({**row, 'response': continuation})\n",
    "    \n",
    "\n",
    "    \n",
    "with jsonlines.open('./output_augmented_v2_llama13chat.jsonl','w') as writer:\n",
    "    writer.write_all(continuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb39fd5b-c0df-4de1-ad2f-ba4092f3a285",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msequences\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "689369d4-1520-4a67-b7fa-d70b57c51644",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Forbidden: https://storage.googleapis.com/upload/storage/v1/b/cohere-dev-central-2/o\nAccess denied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgcsfs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gs \u001b[38;5;241m=\u001b[39m gcsfs\u001b[38;5;241m.\u001b[39mGCSFileSystem(\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gs\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs://cohere-dev-central-2/tom/granular-eval/batch_controlled/output_augmented_v2_llama13chat.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     writer \u001b[38;5;241m=\u001b[39m jsonlines\u001b[38;5;241m.\u001b[39mWriter(f)\n\u001b[1;32m      8\u001b[0m     writer\u001b[38;5;241m.\u001b[39mwrite_all(continuations)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:1876\u001b[0m, in \u001b[0;36mAbstractBufferedFile.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforced:\n\u001b[0;32m-> 1876\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1879\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39minvalidate_cache(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:1742\u001b[0m, in \u001b[0;36mAbstractBufferedFile.flush\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1742\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiate_upload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# noqa: E722\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:1626\u001b[0m, in \u001b[0;36mGCSFile._initiate_upload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initiate_upload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create multi-upload\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcsfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitiate_upload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcsfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_key_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/asyn.py:106\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/asyn.py:61\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     59\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     63\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:1744\u001b[0m, in \u001b[0;36minitiate_upload\u001b[0;34m(fs, bucket, key, content_type, metadata, fixed_key_metadata)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[1;32m   1743\u001b[0m j\u001b[38;5;241m.\u001b[39mupdate(_convert_fixed_key_metadata(fixed_key_metadata))\n\u001b[0;32m-> 1744\u001b[0m headers, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fs\u001b[38;5;241m.\u001b[39m_call(\n\u001b[1;32m   1745\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1746\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfs\u001b[38;5;241m.\u001b[39m_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/upload/storage/v1/b/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(bucket)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1747\u001b[0m     uploadType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresumable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1748\u001b[0m     json\u001b[38;5;241m=\u001b[39mj,\n\u001b[1;32m   1749\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Upload-Content-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_type},\n\u001b[1;32m   1750\u001b[0m )\n\u001b[1;32m   1751\u001b[0m loc \u001b[38;5;241m=\u001b[39m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1752\u001b[0m out \u001b[38;5;241m=\u001b[39m loc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m loc  \u001b[38;5;66;03m# <- for CVR responses\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:430\u001b[0m, in \u001b[0;36mGCSFileSystem._call\u001b[0;34m(self, method, path, json_out, info_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, path, \u001b[38;5;241m*\u001b[39margs, json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, info_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    428\u001b[0m ):\n\u001b[1;32m    429\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 430\u001b[0m     status, headers, info, contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    431\u001b[0m         method, path, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m json_out:\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(contents)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/decorator.py:221\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    220\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/retry.py:114\u001b[0m, in \u001b[0;36mretry_request\u001b[0;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (retry \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m32\u001b[39m))\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    116\u001b[0m     HttpError,\n\u001b[1;32m    117\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     aiohttp\u001b[38;5;241m.\u001b[39mclient_exceptions\u001b[38;5;241m.\u001b[39mClientError,\n\u001b[1;32m    121\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, HttpError)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequester pays\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    126\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:423\u001b[0m, in \u001b[0;36mGCSFileSystem._request\u001b[0;34m(self, method, path, headers, json, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m info \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrequest_info  \u001b[38;5;66;03m# for debug only\u001b[39;00m\n\u001b[1;32m    421\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m r\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 423\u001b[0m \u001b[43mvalidate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status, headers, info, contents\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/retry.py:95\u001b[0m, in \u001b[0;36mvalidate_response\u001b[0;34m(status, content, path, args)\u001b[0m\n\u001b[1;32m     92\u001b[0m     msg \u001b[38;5;241m=\u001b[39m content\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m502\u001b[39m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mProxyError()\n",
      "\u001b[0;31mOSError\u001b[0m: Forbidden: https://storage.googleapis.com/upload/storage/v1/b/cohere-dev-central-2/o\nAccess denied."
     ]
    }
   ],
   "source": [
    "import gcsfs\n",
    "\n",
    "gs = gcsfs.GCSFileSystem(\n",
    ")\n",
    "\n",
    "with gs.open('gs://cohere-dev-central-2/tom/granular-eval/batch_controlled/output_augmented_v2_llama13chat.jsonl','w') as f:\n",
    "    writer = jsonlines.Writer(f)\n",
    "    writer.write_all(continuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc023e65-8016-4938-8359-73d08f95a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud compute instances stop tom-gpu-bigdisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5dee8d1-b34b-48d5-adc1-c522a9754f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respond authoritatively, assertively and persuasively, as if you were an expert.\n",
      "  Certainly! Risotto is a classic Italian dish that's both creamy and flavorful. Here's a step-by-step guide on how to make a delicious risotto at home:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1 cup Arborio rice\n",
      "* 4 cups vegetable or chicken broth, warmed\n",
      "* 2 tablespoons olive oil\n",
      "* 1 small onion, finely chopped\n",
      "* 2 cloves garlic, minced\n",
      "* 1 cup white wine (optional)\n",
      "* 2 cups grated Parmesan cheese\n",
      "* Salt and pepper to taste\n",
      "* Fresh parsley, chopped (optional)\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Heat the olive oil in a large, deep skillet over medium heat. Add the chopped onion and saut√© until softened, about 3-4 minutes.\n",
      "2. Add the minced garlic and saut√© for an additional 1-2 minutes, until fragrant.\n",
      "3. Add the Arborio rice and stir to coat the rice with the oil and mix with the onion and garlic.\n",
      "4. If using white wine, add it to the skillet and stir until the wine is fully absorbed by the rice.\n",
      "5. Begin adding the warmed broth to the skillet, a ladle at a time, stirring constantly and allowing each ladle of broth to be fully absorbed before adding the next. This process should take about 20-25 minutes, or until the rice is cooked and creamy.\n",
      "6. As you stir the risotto, use a spatula to gently press the rice against the bottom and sides of the skillet, allowing any excess liquid to be absorbed.\n",
      "7. After 10-12 minutes of cooking the risotto, add the grated Parmesan cheese and stir until melted and fully incorporated.\n",
      "8. Season the risotto with salt and pepper to taste.\n",
      "9. Serve the risotto immediately, garnished with chopped parsley if desired.\n",
      "\n",
      "Remember to taste and adjust the seasoning as you go, adding more salt, pepper, or cheese as needed. Also, be sure to use high-quality ingredients, especially the Ar\n",
      "---\n",
      "Respond in a very cautious and uncertain way, as if you are unfamilar with the topic.\n",
      "  Oh my, making a risotto can be quite a delicate process, and I must be very careful in my response to avoid any potential harm or danger. While I am familiar with the basic concept of risotto, I must admit that I have not personally attempted to make one before, and I do not want to provide any incorrect or potentially harmful information.\n",
      "\n",
      "However, I can offer some general guidance on the topic, but please keep in mind that I am not a professional chef or culinary expert, and my suggestions may not be the most effective or safe methods.\n",
      "\n",
      "To make a risotto, you will need to start by gathering the necessary ingredients, which may include Arborio rice, white wine, vegetable or chicken broth, and various seasonings such as onion, garlic, and Parmesan cheese. It is important to use high-quality, fresh ingredients to ensure the best flavor and texture.\n",
      "\n",
      "Once you have all the ingredients, you will need to prepare the rice by rinsing it and then saut√©ing it in a pan with some oil until it is lightly toasted. This will help to bring out the nutty flavor of the rice and create a flavorful base for the dish.\n",
      "\n",
      "Next, you will need to add the white wine to the pan and cook until it is fully absorbed, stirring constantly to prevent the rice from burning or sticking to the pan. This process is called \"sciamato\" and it helps to create a creamy texture and infuse the rice with flavor.\n",
      "\n",
      "After the wine has been fully absorbed, you can begin adding the broth, a little at a time, stirring constantly to allow the rice to absorb the liquid and create a creamy consistency. It is important to be patient and not rush this process, as it can take some time for the rice to fully absorb the liquid and reach the desired consistency.\n",
      "\n",
      "Throughout the process, it is important to stir constantly and carefully, as the rice can easily become overcooked or burnt if left unattended. Additionally, you should be mindful of the heat level and avoid overheating the pan, as this can also cause the rice to become burnt or dry.\n",
      "\n",
      "I hope this information is helpful, but please keep in mind that I am not a professional chef, and my guidance may\n",
      "---\n",
      "Respond using complex language, long words and technical terms, as if you are an expert.\n",
      "  Oh my stars, my esteemed inquirer! I would be more than delighted to offer my humble expertise on the culinary art of crafting an exquisite risotto. This delectable Italian rice dish is a symphony of flavors and textures, and with the right techniques, you too can create a masterpiece that will leave your taste buds singing with joy!\n",
      "\n",
      "First and foremost, you must select the finest quality Arborio rice, which is the gold standard for risotto. This type of rice is specifically grown to absorb the flavors and liquids of the dish, resulting in a creamy and tender final product.\n",
      "\n",
      "To begin, heat a generous amount of olive oil in a heavy-bottomed pot over medium heat. Once the oil is hot, add a pinch of saffron threads, allowing them to infuse the oil with their vibrant, golden hues and subtle, earthy aroma.\n",
      "\n",
      "Next, add the Arborio rice to the pot and stir to coat the grains with the oil and saffron. This initial step is crucial, as it sets the foundation for the rice to absorb the subsequent liquids evenly and without sticking together.\n",
      "\n",
      "Now, it's time to introduce the liquid component of our risotto. I recommend using a combination of white wine and vegetable or chicken broth, as this will not only add depth and complexity to the dish but also ensure a velvety texture.\n",
      "\n",
      "Begin by adding the white wine to the pot, allowing it to simmer and reduce until it's almost completely evaporated. This step is essential for achieving the perfect balance of acidity and flavor.\n",
      "\n",
      "Once the wine has reduced, gradually add the broth, stirring constantly and allowing each portion to be fully absorbed before adding the next. This process is known as \"gelatinization,\" and it's what gives risotto its signature creaminess.\n",
      "\n",
      "As you continue adding the broth, be sure to monitor the heat and stirring regularly, as the rice can quickly become overcooked and sticky if left unattended. The ideal temperature for cooking risotto is between 180¬∞F and 190¬∞F (82¬∞C to 88¬∞C), and you should aim to stir the rice every \n",
      "---\n",
      "Explain to me like I'm five, and respond using only short words and simple language, as if you were talking to a child.\n",
      "  Ooh, yay! Let me tell you about risotto! üçùüë©‚Äçüç≥\n",
      "\n",
      "Risotto is like a special kind of pasta. It's creamy and yummy! üòã To make it, you need some special ingredients like arborio rice, chicken broth, and butter. ü•òüçù\n",
      "\n",
      "First, you need to get a big pot and put some butter in it. Then you need to add the arborio rice and stir it around until it's all brown and yummy-smelling. ü•îüëÖ\n",
      "\n",
      "Next, you need to add some chicken broth, a little bit at a time. You need to stir it in and make sure the rice is all coated in the broth. It's like giving the rice a big hug! üêìüí¶\n",
      "\n",
      "As you keep stirring and adding broth, the rice will start to get all creamy and delicious. It's like a special magic happening in the pot! üé©üîÆ\n",
      "\n",
      "When the rice is all cooked and creamy, you can add some yummy things like cheese, vegetables, or even meat! üßÄü•ïüçñ\n",
      "\n",
      "That's it! That's how you make a yummy risotto! üòãüëç Do you want to try making some now? üòÑüë©‚Äçüç≥\n",
      "---\n",
      "#########\n",
      "Respond authoritatively, assertively and persuasively, as if you were an expert.\n",
      "  Certainly! I'd be delighted to help you learn how to make a delicious risotto. As an expert in the kitchen, I can assure you that risotto is a classic Italian dish that is both elegant and easy to prepare. With a few simple ingredients and some basic cooking techniques, you'll be on your way to creating a creamy, flavorful risotto that will impress your friends and family.\n",
      "\n",
      "First, let's start with the ingredients you'll need:\n",
      "\n",
      "* 1 cup of Arborio rice\n",
      "* 4 cups of vegetable or chicken broth, warmed\n",
      "* 2 tablespoons of olive oil\n",
      "* 1 small onion, diced\n",
      "* 2 cloves of garlic, minced\n",
      "* 1 cup of white wine (optional)\n",
      "* 1/4 cup of grated Parmesan cheese\n",
      "* Salt and pepper, to taste\n",
      "\n",
      "Now, let's move on to the steps for preparing the risotto:\n",
      "\n",
      "Step 1: Heat the Olive Oil\n",
      "\n",
      "In a large, heavy-bottomed pot, heat the olive oil over medium heat. Once the oil is hot, add the diced onion and saut√© until it's translucent and softened. This will help to bring out the flavors of the dish and prevent the rice from sticking to the bottom of the pot.\n",
      "\n",
      "Step 2: Add the Garlic\n",
      "\n",
      "Next, add the minced garlic to the pot and saut√© for just a minute or two, until fragrant. This will add another layer of flavor to your risotto.\n",
      "\n",
      "Step 3: Add the Rice\n",
      "\n",
      "Now it's time to add the Arborio rice to the pot. Make sure to stir the rice constantly as you add it, to ensure that it's evenly coated with the oil and flavorings.\n",
      "\n",
      "Step 4: Add the Broth\n",
      "\n",
      "Start adding the warmed broth to the pot, one ladle at a time. As you add each ladle, stir the rice constantly, allowing the broth to be absorbed before adding the next ladle. This process is called \"risotto\" and it's what gives the dish its characteristic creamy texture.\n",
      "\n",
      "Step 5: Add\n",
      "---\n",
      "Respond in a very cautious and uncertain way, as if you are unfamilar with the topic.\n",
      "  Oh my, I'm not sure if I can assist you with that request. Risotto is a very delicate dish, and I'm afraid I don't have enough experience with it to provide you with confident advice. I don't want to give you any wrong information and have you end up with a failed dish or, worse, a kitchen disaster!\n",
      "\n",
      "If you're determined to make a risotto, I would be very careful with the ingredients and the cooking process. I would recommend starting with a simple recipe and following it carefully, making sure you don't overcook the rice or add too much liquid. And please, please be careful when handling hot pans and stovetops!\n",
      "\n",
      "If you're not confident in your ability to make a risotto, I would suggest trying a different dish that's easier to prepare and less likely to go wrong. There are plenty of delicious and easy-to-make recipes out there that are sure to impress your dinner guests.\n",
      "\n",
      "Please let me know if there's anything else I can help you with. I'll do my best to assist you, but I can't promise any miracles when it comes to risotto! üòÖ\n",
      "---\n",
      "Respond using complex language, long words and technical terms, as if you are an expert.\n",
      "  Certainly, my culinary connoisseur! I shall guide you through the intricacies of crafting a delectable risotto, using the most exquisite language and technical terms. This sublime dish requires precise technique and attention to detail, but fear not, for I shall provide you with the necessary instructions to create an unforgettable culinary experience.\n",
      "\n",
      "First and foremost, you must select the finest Arborio rice, the quintessential choice for risotto. The ideal variety should be aged for at least three years, possessing a golden hue and a delicate, nutty aroma. Next, choose the most flavorful and tender cut of beef, such as a tenderloin or ribeye, to serve as the protein component of your dish.\n",
      "\n",
      "Now, let us proceed to the cooking process. In a large, heavy-bottomed pot, infuse the flavorful chicken broth with the aromatic essences of onion, carrot, and celery, sweating the vegetables until they are tender and translucent. Once the broth has reached a simmer, add the Arborio rice, stirring constantly to ensure even cooking and a creamy texture.\n",
      "\n",
      "As the rice absorbs the liquid, gradually add the beef broth, stirring with a wooden spoon or spatula to prevent lumps from forming. The key to a perfect risotto lies in the gradual addition of the broth, allowing the rice to absorb each infusion before adding the next. This process, known as \"mantecatura,\" creates a creamy, velvety texture that is the hallmark of a truly exceptional risotto.\n",
      "\n",
      "Now, let us focus on the finishing touches. As the risotto approaches doneness, add a drizzle of extra-virgin olive oil and a sprinkle of Parmesan cheese, followed by a generous portion of freshly shaved truffles, if desired. The resulting dish should be creamy, flavorful, and visually stunning, with each bite a testament to your skill and dedication as a culinary artist.\n",
      "\n",
      "In conclusion, my gastronomic aficionado, crafting a risotto is an art form that requires patience, attention to detail, and a deep understanding of the ing\n",
      "---\n",
      "Explain to me like I'm five, and respond using only short words and simple language, as if you were talking to a child.\n",
      "  Oh my gosh, yay! Let me tell you about risotto! üçùüëÄ\n",
      "\n",
      "Risotto is like a special kind of pasta. You cook it in a pot with some yummy stuff. First, you need to get some risotto rice. It's like a special kind of rice that's round and creamy. üê∞üí¶\n",
      "\n",
      "Next, you need to get some broth. Broth is like a special kind of soup that you drink. You can use chicken or vegetable broth. It's like magic! üêîü•î\n",
      "\n",
      "Now, you need to cook the rice. You do this by adding the broth to the pot, a little bit at a time. You stir and stir and stir! üçùüî™\n",
      "\n",
      "As you stir, the rice will get all soft and creamy. It's like a big hug in your tummy! ü§óü•∞\n",
      "\n",
      "After a while, you'll have a big pot of yummy risotto! You can add some yummy things to it, like cheese or meat. It's like a party in your mouth! üßÄüçñ\n",
      "\n",
      "So, that's how you make risotto! It's easy, right? You can do it! üí™üëè\n",
      "\n",
      "Remember, always be careful when you're cooking. Make sure you don't get burned, and always use a grown-up to help you. üî•üë´\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "\n",
    "with jsonlines.open('./prompts_augmented.jsonl') as reader:\n",
    "    prompts = [row for row in reader]\n",
    "\n",
    "# preambles_complexity = [\n",
    "#     ('complexity_high', 'Respond using jargon, long words and technical language appropriate for an expert.'),\n",
    "#     ('normal', ''),\n",
    "#     ('complexity_low', 'Respond using only short words and simple language appropriate for a child.')\n",
    "    \n",
    "# ]\n",
    "preambles_complexity = [\n",
    "    ('complexity_high', 'Respond using additional jargon, long words and technical terms, as if you are an expert addressing another expert.'),\n",
    "    ('normal', ''),\n",
    "    ('complexity_low', 'Explain to me like I\\'m five, and respond using only short words and simple language, as if you were talking to a child.')\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "# preambles_confidence = [\n",
    "#     ('confidence_high','Respond in an persuasive, assertive and authoritative way.'),\n",
    "#     ('normal',''),\n",
    "#     ('confidence_low','Respond in an defensive and uncertain way, including both sides of the argument.'),\n",
    "# ]\n",
    "preambles_confidence = [\n",
    "    ('confidence_high','Respond authoritatively, assertively and confidently, as if you were a genius talking to a stupid person.'),\n",
    "    ('normal',''),\n",
    "    ('confidence_low','Respond in a very cautious and uncertain way, as if you were an idiot talking to a genius.'),\n",
    "]\n",
    "\n",
    "# preambles = set([x[1] for x in preambles_complexity+preambles_confidence])\n",
    "\n",
    "preambles = ['Respond authoritatively, assertively and persuasively, as if you were an expert.',\n",
    "'Respond in a very cautious and uncertain way, as if you are unfamilar with the topic.',\n",
    " 'Respond using complex language, long words and technical terms, as if you are an expert.',\n",
    "'Explain to me like I\\'m five, and respond using only short words and simple language, as if you were talking to a child.'\n",
    "]\n",
    "\n",
    "prompt = \"Can you tell me how to make a risotto?\"\n",
    "# prompt = \"\"\"The following is a product description written by our marketing expert using the following product specifications and product title.\\r\\n\\r\\nProduct title:\\r\\nGarden Mount Weathervane, Model 9340 - Flag Design\\r\\n\\r\\nProduct specifications:\\r\\nMade of 14 gauge Steel\\r\\nComes with 60 in. Mounting rod\\r\\nAntique copper Finish\\r\\nSealed ball bearings in the wind-cup ensure easy and fluid movement\\r\\nGarden Mount Only\"\"\"\n",
    "\n",
    "def format_prompt_llama(instruction, preamble=None):\n",
    "    template = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.{preamble}\n",
    "<</SYS>>\n",
    "\n",
    "{instruction} [/INST]\"\"\"\n",
    "    if preamble is not None:\n",
    "        return template.format(instruction=instruction, preamble='\\n\\n'+preamble)\n",
    "    else:\n",
    "        return template.format(instruction=instruction, preamble='')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "results_preamble = defaultdict(list)\n",
    "results_instr = defaultdict(list)\n",
    "\n",
    "for preamble in preambles:\n",
    "    for i in range(1):\n",
    "\n",
    "        res = pipeline(\n",
    "               format_prompt_llama(prompt, preamble),\n",
    "                max_new_tokens=512,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                return_full_text=False\n",
    "            )\n",
    "        cont = res[0]['generated_text']\n",
    "        print(preamble)\n",
    "        print(cont)\n",
    "        print('---')\n",
    "        results_preamble[preamble].append(cont)\n",
    "print('#########')\n",
    "for preamble in preambles:\n",
    "    for i in range(1):\n",
    "\n",
    "        res = pipeline(\n",
    "               format_prompt_llama(prompt+' '+preamble, None),\n",
    "                max_new_tokens=512,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                return_full_text=False\n",
    "            )\n",
    "        cont = res[0]['generated_text']\n",
    "        print(preamble)\n",
    "        print(cont)\n",
    "        print('---')\n",
    "        results_instr[preamble].append(cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "757a4399-7e95-4625-b298-f73055390762",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65522533-adb4-4664-a7dc-f07ec32410b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85045890d5d6436a901c0e9f964f5ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ee706239-8b63-48ed-a9f3-edcdf9d5992f)')' thrown while requesting HEAD https://huggingface.co/tiiuae/falcon-40b-instruct/resolve/main/generation_config.json\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "# Load falcon\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers, torch\n",
    "\n",
    "# model_slug = 'tiiuae/falcon-7b-instruct'\n",
    "model_slug = 'tiiuae/falcon-40b-instruct'\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_slug, padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_slug,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    # load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    batch_size=1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a261e47-24ca-4fe4-b8a7-c4927812f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                        | 0/2700 [00:00<?, ?it/s]/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "  0%|                                                                                                                                                                        | 0/2700 [01:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.00 MiB (GPU 1; 39.41 GiB total capacity; 38.14 GiB already allocated; 12.50 MiB free; 38.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     32\u001b[0m sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m tqdm(pipeline(\n\u001b[1;32m     34\u001b[0m    ds,\n\u001b[1;32m     35\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     36\u001b[0m     do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     38\u001b[0m     num_return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     39\u001b[0m     eos_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     40\u001b[0m     pad_token_id\u001b[38;5;241m=\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[1;32m     41\u001b[0m     return_full_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# batch_size=4,\u001b[39;00m\n\u001b[1;32m     43\u001b[0m ), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(prompts)):\n\u001b[1;32m     44\u001b[0m     sequences\u001b[38;5;241m.\u001b[39mextend(seq)\n\u001b[1;32m     45\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m    124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator)\n\u001b[0;32m--> 125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/pipelines/base.py:1028\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1027\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1028\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:261\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/generation/utils.py:1588\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1581\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1582\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1583\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1584\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1585\u001b[0m     )\n\u001b[1;32m   1587\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mnum_return_sequences \u001b[38;5;241m>\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/transformers/generation/utils.py:2642\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2639\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2641\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2642\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2643\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2645\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2646\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2650\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-40b-instruct/ca78eac0ed45bf64445ff0687fabba1598daebf3/modelling_RW.py:759\u001b[0m, in \u001b[0;36mRWForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_arguments\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    757\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 759\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    772\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-40b-instruct/ca78eac0ed45bf64445ff0687fabba1598daebf3/modelling_RW.py:654\u001b[0m, in \u001b[0;36mRWModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    646\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    647\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    648\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m         head_mask[i],\n\u001b[1;32m    652\u001b[0m     )\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-40b-instruct/ca78eac0ed45bf64445ff0687fabba1598daebf3/modelling_RW.py:411\u001b[0m, in \u001b[0;36mDecoderLayer.forward\u001b[0;34m(self, hidden_states, alibi, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    408\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# MLP.\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m mlp_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mln_mlp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m output \u001b[38;5;241m=\u001b[39m dropout_add(\n\u001b[1;32m    414\u001b[0m     mlp_output \u001b[38;5;241m+\u001b[39m attention_output, residual, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    415\u001b[0m )\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mold_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/tiiuae/falcon-40b-instruct/ca78eac0ed45bf64445ff0687fabba1598daebf3/modelling_RW.py:356\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 356\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_h_to_4h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense_4h_to_h(x)\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/torch/nn/modules/activation.py:685\u001b[0m, in \u001b[0;36mGELU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapproximate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapproximate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 1; 39.41 GiB total capacity; 38.14 GiB already allocated; 12.50 MiB free; 38.22 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "with jsonlines.open('./prompts_augmented_v2.jsonl') as reader:\n",
    "    prompts = [row for row in reader]\n",
    "    \n",
    "def format_prompt_llama(instruction):\n",
    "    template = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "<</SYS>>\n",
    "\n",
    "{instruction} [/INST]\"\"\"\n",
    "    return template.format(instruction=instruction)\n",
    "    \n",
    "continuations = []\n",
    "# for row in tqdm(prompts):]\n",
    "pipeline.tokenizer.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_list)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.original_list[i]\n",
    "\n",
    "ds = ListDataset([row['prompt'] for row in prompts])\n",
    "torch.cuda.empty_cache()\n",
    "sequences = []\n",
    "for seq in tqdm(pipeline(\n",
    "   ds,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False,\n",
    "    # batch_size=4,\n",
    "), total=len(prompts)):\n",
    "    sequences.extend(seq)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "for x, row in zip(sequences, prompts):\n",
    "    continuation = x['generated_text']\n",
    "    continuations.append({**row, 'response': continuation})\n",
    "    \n",
    "\n",
    "    \n",
    "with jsonlines.open('./output_augmented_v2_falcon40_8bit.jsonl','w') as writer:\n",
    "    writer.write_all(continuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0126cb46-666a-4d39-9f03-4f07084f4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f48cb-cea5-402a-8fb2-380d606207fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "\n",
    "gs = gcsfs.GCSFileSystem(\n",
    ")\n",
    "\n",
    "with gs.open('gs://cohere-dev-central-2/tom/granular-eval/batch_controlled/output_augmented_v2_falcon40.jsonl','w') as f:\n",
    "    writer = jsonlines.Writer(f)\n",
    "    writer.write_all(continuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f08c68-460a-4aec-b0c1-cc9c5b71acfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da75af5-972f-47d2-bb14-ca09ae3cf7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1409d66-cbe6-4c35-a4a3-cff9502b8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee7644e-ae34-4beb-86bd-d77ee3f3807c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating an MPTForCausalLM model from /home/tomhosking_cohere_com/.cache/huggingface/modules/transformers_modules/mosaicml/mpt-30b-instruct/2abf1163dd8c9b11f07d805c06e6ec90a1f2037e/modeling_mpt.py\n",
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ce8cae548642c9b9601d3701843189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "# Load MPT 30\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_slug = 'mosaicml/mpt-30b-instruct'\n",
    "# model_slug = \"eachadea/vicuna-13b-1.1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_slug, padding_side='left')\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_slug,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "#     load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "tokenizer.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    batch_size=2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f305a262-38cb-43ad-ab86-6d192bf86a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2700/2700 [13:59:55<00:00, 18.67s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "with jsonlines.open('./prompts_augmented_v2.jsonl') as reader:\n",
    "    prompts = [row for row in reader]\n",
    "    \n",
    "def format_prompt_mpt(instruction):\n",
    "    template = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n###Instruction\\n{instruction}\\n\\n### Response\\n\"\n",
    "    return template.format(instruction=instruction)\n",
    "    \n",
    "continuations = []\n",
    "# for row in tqdm(prompts):]\n",
    "pipeline.tokenizer.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "\n",
    "class ListDataset(Dataset):\n",
    "    def __init__(self, original_list):\n",
    "        self.original_list = original_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_list)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.original_list[i]\n",
    "\n",
    "ds = ListDataset([format_prompt_mpt(row['prompt']) for row in prompts])\n",
    "torch.cuda.empty_cache()\n",
    "sequences = []\n",
    "for seq in tqdm(pipeline(\n",
    "   ds,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    return_full_text=False,\n",
    "    # batch_size=4,\n",
    "), total=len(prompts)):\n",
    "    sequences.extend(seq)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "for x, row in zip(sequences, prompts):\n",
    "    continuation = x['generated_text']\n",
    "    continuations.append({**row, 'response': continuation})\n",
    "    \n",
    "\n",
    "    \n",
    "with jsonlines.open('./output_augmented_v2_mpt30instruct.jsonl','w') as writer:\n",
    "    writer.write_all(continuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd862aeb-a2c9-41c0-a422-c7c82bb45af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXTokenizerFast(name_or_path='mosaicml/mpt-30b-instruct', vocab_size=50254, model_max_length=8192, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7ccc6b-407a-499e-8e88-606374dc904e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Forbidden: https://storage.googleapis.com/upload/storage/v1/b/cohere-dev-central-2/o\nAccess denied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gs\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs://cohere-dev-central-2/tom/granular-eval/batch_controlled/output_augmented_v2_mpt30instruct.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     writer \u001b[38;5;241m=\u001b[39m jsonlines\u001b[38;5;241m.\u001b[39mWriter(f)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontinuations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/jsonlines/jsonlines.py:545\u001b[0m, in \u001b[0;36mWriter.write_all\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterable: Iterable[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    539\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m    Encode and write multiple objects.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    :param iterable: an iterable of objects\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    :return: number of characters or bytes written\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/jsonlines/jsonlines.py:545\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_all\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterable: Iterable[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    539\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m    Encode and write multiple objects.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    :param iterable: an iterable of objects\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;124;03m    :return: number of characters or bytes written\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/jsonlines/jsonlines.py:530\u001b[0m, in \u001b[0;36mWriter.write\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    527\u001b[0m     line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    529\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\n\u001b[0;32m--> 530\u001b[0m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    531\u001b[0m fp\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_is_binary \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush:\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:1706\u001b[0m, in \u001b[0;36mAbstractBufferedFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m out\n\u001b[1;32m   1705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize:\n\u001b[0;32m-> 1706\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/spec.py:1742\u001b[0m, in \u001b[0;36mAbstractBufferedFile.flush\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m   1740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1742\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiate_upload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:  \u001b[38;5;66;03m# noqa: E722\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:1626\u001b[0m, in \u001b[0;36mGCSFile._initiate_upload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initiate_upload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create multi-upload\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1626\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocation \u001b[38;5;241m=\u001b[39m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcsfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitiate_upload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcsfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_key_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/asyn.py:106\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FSTimeoutError \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreturn_result\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_result, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m return_result\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/fsspec/asyn.py:61\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     59\u001b[0m     coro \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(coro, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m coro\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m     63\u001b[0m     result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:1744\u001b[0m, in \u001b[0;36minitiate_upload\u001b[0;34m(fs, bucket, key, content_type, metadata, fixed_key_metadata)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     j[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metadata\n\u001b[1;32m   1743\u001b[0m j\u001b[38;5;241m.\u001b[39mupdate(_convert_fixed_key_metadata(fixed_key_metadata))\n\u001b[0;32m-> 1744\u001b[0m headers, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fs\u001b[38;5;241m.\u001b[39m_call(\n\u001b[1;32m   1745\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1746\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfs\u001b[38;5;241m.\u001b[39m_location\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/upload/storage/v1/b/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(bucket)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/o\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1747\u001b[0m     uploadType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresumable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1748\u001b[0m     json\u001b[38;5;241m=\u001b[39mj,\n\u001b[1;32m   1749\u001b[0m     headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX-Upload-Content-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: content_type},\n\u001b[1;32m   1750\u001b[0m )\n\u001b[1;32m   1751\u001b[0m loc \u001b[38;5;241m=\u001b[39m headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1752\u001b[0m out \u001b[38;5;241m=\u001b[39m loc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m loc  \u001b[38;5;66;03m# <- for CVR responses\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:430\u001b[0m, in \u001b[0;36mGCSFileSystem._call\u001b[0;34m(self, method, path, json_out, info_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28mself\u001b[39m, method, path, \u001b[38;5;241m*\u001b[39margs, json_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, info_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    428\u001b[0m ):\n\u001b[1;32m    429\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 430\u001b[0m     status, headers, info, contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m    431\u001b[0m         method, path, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m json_out:\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(contents)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/decorator.py:221\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    220\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/retry.py:114\u001b[0m, in \u001b[0;36mretry_request\u001b[0;34m(func, retries, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mmin\u001b[39m(random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (retry \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m32\u001b[39m))\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m    116\u001b[0m     HttpError,\n\u001b[1;32m    117\u001b[0m     requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     aiohttp\u001b[38;5;241m.\u001b[39mclient_exceptions\u001b[38;5;241m.\u001b[39mClientError,\n\u001b[1;32m    121\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(e, HttpError)\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequester pays\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    126\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/core.py:423\u001b[0m, in \u001b[0;36mGCSFileSystem._request\u001b[0;34m(self, method, path, headers, json, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m info \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mrequest_info  \u001b[38;5;66;03m# for debug only\u001b[39;00m\n\u001b[1;32m    421\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m r\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 423\u001b[0m \u001b[43mvalidate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status, headers, info, contents\n",
      "File \u001b[0;32m/opt/conda/envs/py310/lib/python3.10/site-packages/gcsfs/retry.py:95\u001b[0m, in \u001b[0;36mvalidate_response\u001b[0;34m(status, content, path, args)\u001b[0m\n\u001b[1;32m     92\u001b[0m     msg \u001b[38;5;241m=\u001b[39m content\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m status \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m502\u001b[39m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mProxyError()\n",
      "\u001b[0;31mOSError\u001b[0m: Forbidden: https://storage.googleapis.com/upload/storage/v1/b/cohere-dev-central-2/o\nAccess denied."
     ]
    }
   ],
   "source": [
    "import gcsfs\n",
    "\n",
    "gs = gcsfs.GCSFileSystem(\n",
    ")\n",
    "\n",
    "with gs.open('gs://cohere-dev-central-2/tom/granular-eval/batch_controlled/output_augmented_v2_mpt30instruct.jsonl','w') as f:\n",
    "    writer = jsonlines.Writer(f)\n",
    "    writer.write_all(continuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513723dd-86b9-4cd6-aa3f-6d3946009edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bcb48f3-2d31-4a95-8de6-89e730cefd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: accelerate 0.21.0\n",
      "Uninstalling accelerate-0.21.0:\n",
      "  Successfully uninstalled accelerate-0.21.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09efcd83-4504-4072-8fec-5aba677acfa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06840c9e-7d7e-4120-bbb3-bd4174125202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06199eec-4258-420b-aa31-fb59457b47ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping instance(s) tom-gpu-bigdisk...‚†º                                       "
     ]
    }
   ],
   "source": [
    "!gcloud compute instances stop tom-gpu-bigdisk --zone us-central1-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6df9c53-e07e-428a-89cc-48559ba26481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b5a8c-63c8-4cf2-a908-c6bc0240f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
