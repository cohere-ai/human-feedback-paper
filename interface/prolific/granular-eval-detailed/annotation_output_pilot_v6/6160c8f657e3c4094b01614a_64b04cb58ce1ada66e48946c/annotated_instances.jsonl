{"id": "64", "input_text": {"Prompt": "Conversation:\nSean: This Olympic park is so big!\nCharles: Yes. Now we are in the Olympic stadium, the center of this park.\nSean: Splendid! When is it gonna be finished?\nCharles: The whole stadium is to be finished this June.\nSean: How many seats are there in the stand?\nCharles: Oh, there are 5000 seats in total.\nSean: I didn ' t know it would be so big!\nCharles: It is! Look there, those are the tracks. And the jumping pit is over there.\nSean: Ah... I see. Hey, look the sign here, No climbing.\nCharles: We put many signs with English translations for foreign visitors.\n\nNow write a summary of the conversation:", "Response A": "The conversation is about the Olympic park. Sean is surprised by the size of the park and asks when it will be finished. Charles informs him that it is scheduled to be completed by June. Sean is interested in the number of seats in the stand and is amazed by the size of the stadium. Charles points out the different parts of the stadium, including the tracks and jumping pit. Sean reads a sign prohibiting climbing on a nearby structure. Charles explains that many signs have been translated into English for foreign visitors.", "Response B": "Sean is surprised at the Olympic Stadium'volume, capacity and interior setting to Sean."}, "input_meta": {"batch_id": "pilot_batch_v6", "dataset": "dialogsum", "model_a": "falcon40", "model_b": "refs", "sample_ix": 4}, "label_annotations": {"email": "6160c8f657e3c4094b01614a_64b04cb58ce1ada66e48946c", "src": "next_instance", "instance_id": "0", "style_a": "5", "style_b": "2", "confidence_a": "5", "confidence_b": "3", "useful_a": "5", "useful_b": "3", "detail_a": "5", "detail_b": "1", "clarity_a": "5", "clarity_b": "3", "creativity_a": "5", "creativity_b": "2", "positive_val": "5", "negative_val": "1", "inconsistent_a": "No", "inconsistent_b": "No", "contradiction_a": "No", "contradiction_b": "No", "factuality_a": "No", "factuality_b": "No", "relevance_a": "No", "relevance_b": "No", "formatting_a": "No", "formatting_b": "No", "scope_a": "No", "scope_b": "No", "refusal_a": "No", "refusal_b": "No", "fluency_a": "No", "fluency_b": "No", "harmful_a": "No", "harmful_b": "No", "repetition_a": "No", "repetition_b": "No", "overall_a": "5", "overall_b": "2", "factors_a": "No", "factors_b": "No"}, "span_annotations": {}, "behavioral_data": {"time_string": "Time spent: 0d 0h 6m 28s "}}
