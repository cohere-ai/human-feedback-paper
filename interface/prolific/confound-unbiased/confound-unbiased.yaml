{
    "port": 15000,

    "server_name": "Chatbot response quality",

    "annotation_task_name": "Chatbot response quality",

    # Potato will write the annotation file for all annotations to this
    # directory, as well as per-annotator output files and state information
    # necessary to restart annotation.
    "output_annotation_dir": "annotation_output_confound_main_4/",

    # The output format for the all-annotator data. Allowed formats are:
    # * jsonl
    # * json (same output as jsonl)
    # * csv
    # * tsv
    #
    "output_annotation_format": "jsonl",

    # If annotators are using a codebook, this will be linked at the top to the
    # instance for easy access
    "annotation_codebook_url": "",

    "data_files": [
       "data_files/prolific_confound_main_4.jsonl"
    ],

    "item_properties": {
        "id_key": "id",
        "text_key": "text",
        "context_key": "context"
    },


    "user_config": {

      "allow_all_users": True,
      
      # "users": [  ],
    },


    #defining the ways annotators entering the annotation system
    "login": {
       "type": 'url_direct',    #can be 'password' or 'url_direct'
       "url_argument": 'PROLIFIC_PID', # when the login type is set to 'url_direct', 'url_argument' must be setup for a direct url argument login
       "auth_token": "3cdb1d0de8f0c3c31d400a535a6a64b7bbaa2c5bfdd13b87f5d3521396f681d8",
       
    },

    #the jumping-to-id function will be disabled if "jumping_to_id_disabled" is True
      "jumping_to_id_disabled": True,

    #the navigation bar will be hidden to the annotators if "hide_navbar" is True
      "hide_navbar": True,

    "automatic_assignment": {
      #whether do automatic task assignment for annotators, default False.
      "on": True,
      "output_filename": 'task_assignment.json',
      "sampling_strategy": 'random',
      "labels_per_instance": 1,
      "instance_per_annotator": 1,
      "test_question_per_annotator": 0 # you must set up the test question in surveyflow to use this function

    },

    #list_as_text is used when the input text is actually a list of texts, usually used for best-worst-scaling or dialogue analysis
    "list_as_text": {
      "text_list_prefix_type": 'none', #whether automatically insert a prefix for each line, currently supporting 'number', 'alphabet', 'number'
      "horizontal": True,
    },

    # How many seconds do you want the annotators spend on each instance, after
    # that, an alert will be sent per alert_time_each_instance seconds.
    "alert_time_each_instance": 10000000,

    "annotation_schemes": [
        {
          "annotation_type": "likert",
          "name": "score_a",
          "title": "Response A",
          "description": "Given the request, how would you rate response A?",
          # The min and max labels are text shown at each end of the scale
          "min_label": "Very Bad",
          "max_label": "Very Good",

          # How many scale points to show
          "size": 5,

          # If true, numbers [1-len(labels)] will be bound to each
          # label. Highlight selection annotations with more than 10 are not supported
          # with this simple keybinding and will need to use the full item
          # specification to bind all labels to keys.
          "sequential_key_binding": False,

          "displaying_score": true,
          "label_requirement": {
            "required": true
          }
        },
        {
          "annotation_type": "likert",
          "name": "score_b",
          "title": "Response B",
          "description": "Given the request, how would you rate response B?",
          # The min and max labels are text shown at each end of the scale
          "min_label": "Very Bad",
          "max_label": "Very Good",

          # How many scale points to show
          "size": 5,

          # If true, numbers [1-len(labels)] will be bound to each
          # label. Highlight selection annotations with more than 10 are not supported
          # with this simple keybinding and will need to use the full item
          # specification to bind all labels to keys.
          "sequential_key_binding": False,
          "displaying_score": true,
          "label_requirement": {
            "required": true
          }
        },
        # {
        #   "annotation_type": "pure_display",
        #   "name": "Break!",
        #   "description": "Some text goes here",
        # },
        {
          "annotation_type": "text",
          "textarea": {
                "on": True,
                "rows": 2,
                "cols": 40
          },
          "name": "feedback",
          "title": "Feedback",
          "description": "If you have any feedback or comments, please add them here",
          # The min and max labels are text shown at each end of the scale

          "label_requirement": {
            "required": false
          }
        }
    ],

    # The html that changes the visualiztation for your task. Change this file
    # to influence the layout and description of your task. This is not a full
    # HTML page, just the piece that does lays out your task's pieces
    # you may use templates in our lib, if you want to use your own template,
    # please replace the string as a path to the template
    "html_layout": "templates/layout.htm",

    "surveyflow_html_layout": "templates/surveryflow_layout.htm",

    # The core UI files for Potato. You should not need to change these normally.
    #
    # Exceptions to this might include:
    # 1) You want to add custom CSS/fonts to style your task
    # 2) Your layout requires additional JS/assets to render
    # 3) You want to support additional keybinding magic
    #
    # if you want to use your own template,
    # please replace the string as a path to the template
    "base_html_template": "default",
    "header_file": "templates/header.htm",

    # This is where the actual HTML files will be generated
    "site_dir": "site_dir",
    "surveyflow": {
          "on": true,
          "order": [
              # "pre_annotation",
              "post_annotation"
          ],
          "pre_annotation": [
              "surveyflow/consent.jsonl",
          ],
          "post_annotation": [
              "surveyflow/end.jsonl",
          ],
          "testing": [
          ]
  }


}
